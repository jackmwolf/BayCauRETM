---
title: "Bayesian Causal Inference for Recurrent Events with Timing Misalignment"
author: "Yuqin"
date: "2025-08-15"
output:
  pdf_document:
    latex_engine: lualatex
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = TRUE, fig.width = 11, fig.height = 8.5, dpi = 150, fig.align = "center")

library(BayCauRETM)
library(dplyr)
library(tidyr)
library(rstan)
library(parallel)
library(rstudioapi)
set.seed(42)
```

This Markdown of the Bayesian framework was proposed by Oganisian et al. (2024) for causal inference with recurrent events subject to timing misalignment. We use a semiparametric Bayesian model to estimate the average causal effect of a time-varying treatment on the recurrent event rate, accounting for terminal events and censoring.

## 1. Setup

We configure Stan and set parallelization options for efficient MCMC workflow. We fix the random seed, enable parallel sampling, and set Hamiltonian Monte Carlo controls. The defaults (warmup = 500, M (posterior draws) = 500, 4 chains) are modest for illustration.

```{r}
use_multicore <- TRUE   # FALSE for single core
if (use_multicore) {
  cores <- max(1, detectCores() - 2)
} else {
  cores <- 1
}
options(mc.cores = cores)
rstan_options(auto_write = TRUE)

B      <- 50
s_vec  <- c(3, 6, 9)
```

## 2. Data Preprocessing

This step prepares the longitudinal dataset for analysis, including normalization and handling of missing values.

The package expects a long panel with: unique subject id ($id$), discrete time index ($k$), treatment ($A_k$), recurrent count ($Y_k$), terminal event indicator ($T_k$), and optional covariates (here $L.1$, $L.2$).

History $lagY_k$ (default 0 at each subject’s first interval) captures short-term dependence. In our design, lagged history terms are fully flexible: users may supply their own lag variables (e.g., lagYk, higher-order lags, or custom functions of past outcomes) directly in the dataset and reference them in the formulas, or omit them entirely. If no lag variable is provided but lag terms are specified in the formulas, the function automatically constructs the appropriate lag internally. This guarantees valid defaults while allowing investigators to encode any history structure they need.

Continuous covariates are standardized to improve sampler geometry and prior interpretability. Remove observations with missing values for variables used in the model formulas. K equals the number of unique time intervals and controls the length of each model’s piecewise baseline.

```{r}
load("data.Rdata")
df_fit <- df %>%
  filter(id %in% 1:100) %>%           #for subset
  arrange(id, k) %>%
  mutate(k_fac = as.integer(factor(k, levels = sort(unique(k))))) %>%
  group_by(id) %>%
  mutate(
    lagYk = if ("lagYk" %in% names(.)) replace_na(lagYk, 0) else lag(Yk, default = 0)
  ) %>%
  ungroup() %>%
  drop_na(Tk, Yk, Ak, L.1, L.2) %>%
  mutate(
    L.1 = as.numeric(scale(L.1)),
    L.2 = as.numeric(scale(L.2))
  )
K <- length(unique(df_fit$k_fac))
```

## 3. Bayesian Model Fitting

We now fit the joint model for the recurrent events and terminal process using Stan.

We fit a joint Bayesian model for (i) the terminal process $T_k$ and (ii) the recurrent events $Y_k$, sharing the discrete time structure and history records. Each sub-model includes: the current treatment, lagged outcomes (e.g., $I(\text{lagY}_k^2)$), standardized covariates $(L.1, L.2)$, and a piecewise-constant baseline (time_baseline_T[k], time_baseline_Y[k]).

Following Oganisian et al. (2024), we use $\beta$ to denote coefficients in the terminal (death) model and $\theta$ to denote coefficients in the recurrent-event model. We expose variable names in diagnostics and summaries as follows:

- $\beta_{T:L.1},\ \beta_{T:L.2}$: covariate ($L.1$, $L.2$ here) effects in the terminal ($T$) model.

- $\theta_{Y:L.1},\ \theta_{Y:L.2}$: covariate ($L.1$, $L.2$ here) effects in the recurrent-event ($Y$) model.

- $\theta_{Y,\text{lag}:I(\text{lagYk}^2)}$: coefficients for lagged outcome features in the recurrent-event model.

- time_baseline_T[j], time_baseline_Y[j]: $j$-th time-interval baselines capturing secular time trends.

- treatment_effect_T, treatment_effect_Y: treatment effects for the terminal and recurrent processes, respectively.


```{r}
# Stan fit
fit <- fit_causal_recur(
  data      = df_fit,
  K         = K,
  id_col    = "id",
  time_col  = "k_fac",
  treat_col = "Ak",
  lag_col   = "lagYk",
  formula_T = Tk ~ Ak + I(lagYk^2) + L.1 + L.2,
  formula_Y = Yk ~ Ak + I(lagYk^2) + L.1 + L.2,
  cores     = cores,
  verbose   = TRUE
)
```

## 4. MCMC Diagnostics

Evaluate convergence and identify any problematic chains. We report R-hat (target ≈ 1.00), effective sample size (should be large), and show traceplots grouped by model block.
By default, the mcmc_diagnosis() and its plot function checks multiple model blocks, including the T-model, Y-model, treatment effects, and lag terms. However, for simplicity and clarity, users can focus on a specific component as follows.
Specifically, "T-model" refers to the baseline hazard and covariate effects in the terminal event model, while "Y-model" targets the same components in the recurrent event model. "treatment_effect_T" and "treatment_effect_Y" refer to the treatment effects in the T-model and Y-model, respectively. "Lag" corresponds to the lag kernel terms that capture dependencies across time. These names can be supplied directly to the pars argument in the plot() call, and matching is case-insensitive and supports partial keyword matching for convenience. P corresponds to the columns of the design matrices L_Tk and L_Yk constructed from formula_T and formula_Y.

```{r}
# MCMC Diagnosis
rstan::check_hmc_diagnostics(fit$stan_fit)
diag <- mcmc_diagnosis(fit)
plot(diag, pars = "T-model") 
```

```{r}
# Extract posterior draws for covariate coefficients (beta_L and theta_L)
post <- rstan::extract(fit$stan_fit)

# Covariate coefficient draws (iterations * P)
betaL_draws  <- post$betaL
thetaL_draws <- post$thetaL

# Posterior means and 95% Credible Interval
betaL_sum <- apply(betaL_draws, 2, function(x) c(mean=mean(x), quantile(x, c(.025,.975))))
thetaL_sum <- apply(thetaL_draws, 2, function(x) c(mean=mean(x), quantile(x, c(.025,.975))))

betaL_sum
thetaL_sum
```


## 5. G-Computation

We evaluate treatment–start strategies $s\in\mathcal S$ over intervals $k=1,\dots,K$ using Bayesian g-computation with death as a terminal event. For subject $i$, under strategy $s$ we simulate recurrent counts $Y_{ik}^{(m)}(s)$ and the not-at-risk indicator $T_{ik}^{(m)}(s)\in\{0,1\}$ (equals 1 from the first interval after death). Let $L_i$ be the subject’s baseline covariate vector. Our estimand is

$$
\theta_s(K)
=\mathbb{E}\!\left[
\frac{\sum_{k=1}^{K} Y_{ik}^{(m)}(s)}
     {K-\sum_{k=1}^{K} T_{ik}^{(m)}(s)}
\right],
$$

and the contrast $\Delta(s,s')=\theta_s(K)-\theta_{s'}(K)$. In the package we set $s'=K+1$ as the reference (“never treat”).

For each posterior draw $m$, g_computation() approximates the conditional expectation given $L_i$ by averaging over $B$ Monte-Carlo replicates:

$$
R_i^{(m)}(s)
=\frac{1}{B}\sum_{b=1}^{B}
\left[
\frac{\sum_{k=1}^{K} Y_{ikb}^{(m)}(s)}
     {K-\sum_{k=1}^{K} T_{ikb}^{(m)}(s)}
\right].
$$

Then it integrates over the baseline distribution of $L$ using Dirichlet weights $\pi_i^{(m)}$ (Bayesian bootstrap):

$$
\theta_s^{(m)}(K)=\sum_{i=1}^{n}\pi_i^{(m)} R_i^{(m)}(s),
\qquad
\Delta^{(m)}(s)=\theta_s^{(m)}(K)-\theta_{K+1}^{(m)}(K).
$$

Posterior draws $\{\Delta^{(m)}(s)\}_m$ are summarized by their mean and 95% credible interval. For clarity, although we construct a baseline covariate data frame below for illustration, the g_computation() function performs marginalization over baseline covariates internally using Bayesian bootstrap weights, and this object is not explicitly passed to the function.


```{r}
baseline_df <- fit$data_preprocessed %>%
  group_by(pat_id) %>%
  slice_min(order_by = k_idx, n = 1) %>%
  arrange(pat_id) %>%
  ungroup()

# Note: baseline_df is created for illustration only.
# The g_computation() function marginalizes over baseline covariates internally
# via Bayesian bootstrap weights and does not require this object as input.

gcomp <- g_computation(
  fit_out = fit,
  s_vec   = s_vec,
  B       = B,
  cores   = 1
)

print(gcomp)
plot(gcomp, ref_line = 0)
plot(gcomp, interactive = TRUE, ref_line = 0)
```

## 6. Switching Probability Summary

The switching probability summary quantifies how often subjects switch treatment across follow-up intervals. For each interval k, we estimate the within-subject probability of switching.

The switching probability summary quantifies how often subjects change treatment across follow-up intervals.\
There are two possible scales:

-   Mass (default): the marginal probability that switching occurs at interval k, which shows how many subjects in the population switched at each time point.
-   Hazard: the conditional probability of switching at interval k given that the subject has not yet switched before k.

By default, the function uses scale="mass":

```{r}
# default (scale="mass")
sw  <- switching_probability_summary(fit$data_preprocessed, covariates = c("L.1", "L.2"), scale="mass")          
plot(sw)
```

```{r}
sw  <- switching_probability_summary(fit$data_preprocessed, covariates = c("L.1", "L.2"), scale="hazard")
plot(sw)
```

## 7. Summary of Causal Estimates

This table summarizes posterior distributions of model parameters and g-computation estimates. Parameter tables report Mean, 2.5%, 97.5%, R-hat, n_eff, MCSE, and CI width. Effects close to 0 with tight intervals imply little evidence of impact. Baseline blocks (time_baseline\_\*) quantify secular time risk; do not interpret them as treatment effects.

```{r}
sum_tbl <- result_summary_table(
  fit_out   = fit,
  gcomp_out = gcomp,
  s_vec     = s_vec,
  format    = "kable"
)
print(sum_tbl)
```
